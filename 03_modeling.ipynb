{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.base import TransformerMixin\n",
    "from nltk.corpus import stopwords\n",
    "from scripts import remove_links, find_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train_nolinks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text', 'target', 'text_nolinks',\n",
       "       'text_nl_hashtag', 'text_nl_ht_keyword'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train['text_nl_hashtag']\n",
    "y = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Noah C.'s Week 5 Lab Review\n",
    "# originally adapted from:\n",
    "# https://stackoverflow.com/questions/28384680/scikit-learns-pipeline-a-sparse-matrix-was-passed-but-dense-data-is-required\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_nb = {\n",
    "    'cv__lowercase': [True, False],\n",
    "    'cv__stop_words': [None, 'english'],\n",
    "    'cv__max_features': [None, 8000],\n",
    "    'cv__ngram_range': [(1,1),(1,2)],\n",
    "    'cv__min_df': [1, 3, 5],\n",
    "    'cv__max_df': [.8],\n",
    "    'tf__use_idf': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb = Pipeline([('cv', CountVectorizer()),\n",
    "                    ('tf', TfidfTransformer()),\n",
    "                    ('nb', MultinomialNB())\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lr = {\n",
    "    'cv__lowercase': [True],\n",
    "    'cv__stop_words': [None, 'english'],\n",
    "    'cv__max_features': [None],\n",
    "    'cv__ngram_range': [(1,1),(1,2)],\n",
    "    'cv__min_df': [1],\n",
    "    'cv__max_df': [.6, .80, .9],\n",
    "    'tf__use_idf': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('cv', CountVectorizer()),\n",
    "                    ('tf', TfidfTransformer()),\n",
    "                    ('lr', LogisticRegression())\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the baseline score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.570328\n",
       "1    0.429672\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline score is **approximately 57%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from Patrick Wales-Dinan's demonstration on saving GridSearches\n",
    "class GridSearchContainer:\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y,\n",
    "                                                                                random_state=42,\n",
    "                                                                                stratify = y)\n",
    "        self.model_params = {}\n",
    "        self.best_models = []\n",
    "        self.model_df = pd.DataFrame\n",
    "        self.count = 0\n",
    "        \n",
    "    def search(self, estimator, params, mod_name='model', evaluator='f1'):\n",
    "            gs = GridSearchCV(estimator,\n",
    "                  param_grid = params,\n",
    "                  verbose = 2,\n",
    "                  cv = 5,\n",
    "                  n_jobs=-1,\n",
    "                  scoring = evaluator)\n",
    "            \n",
    "            gs.fit(self.X_train, self.y_train)\n",
    "            print(f\"Train {evaluator}: {gs.score(self.X_train, self.y_train)}\")\n",
    "            print(f\"Test {evaluator}: {gs.score(self.X_test, self.y_test)}\")\n",
    "            gs.best_params_[evaluator] = gs.best_score_\n",
    "            \n",
    "            self.model_params[f'{mod_name}_{self.count}'] = gs.best_params_\n",
    "            self.model_df = pd.DataFrame.from_dict(self.model_params, orient='index')\n",
    "            self.model_df.sort_values(by=evaluator, ascending=False, inplace=True)\n",
    "            self.best_models.append((gs.best_estimator_, gs.best_score_))\n",
    "            self.count+=1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsc = GridSearchContainer(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1: 0.8159181858603823\n",
      "Test f1: 0.7480211081794195\n"
     ]
    }
   ],
   "source": [
    "gsc.search(pipe_nb, params_nb, 'nb_f1', 'f1')\n",
    "# gsc.search(pipe_lr, params_lr, 'lr_f1', 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv__lowercase</th>\n",
       "      <th>cv__max_df</th>\n",
       "      <th>cv__max_features</th>\n",
       "      <th>cv__min_df</th>\n",
       "      <th>cv__ngram_range</th>\n",
       "      <th>cv__stop_words</th>\n",
       "      <th>tf__use_idf</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nb_f1_0</th>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>False</td>\n",
       "      <td>0.730895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cv__lowercase  cv__max_df cv__max_features  cv__min_df  \\\n",
       "nb_f1_0           True         0.8             None           3   \n",
       "\n",
       "        cv__ngram_range cv__stop_words  tf__use_idf        f1  \n",
       "nb_f1_0          (1, 1)        english        False  0.730895  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsc.model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv',\n",
       "                 CountVectorizer(max_df=0.8, min_df=3, stop_words='english')),\n",
       "                ('tf', TfidfTransformer(use_idf=False)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsc.best_models[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb = gsc.best_models[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv',\n",
       "                 CountVectorizer(max_df=0.8, min_df=3, stop_words='english')),\n",
       "                ('tf', TfidfTransformer(use_idf=False)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_nb.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Probabilities Dataframe\n",
    "\n",
    "Now I want to create a dataframe that has the probabilities of an observation (post) being classified as belonging to the `poppunkers` or `punk` subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_df(model):\n",
    "    '''\n",
    "    Pass your best model through this function. Returns a dataframe containing:\n",
    "    - orig_post: the original post\n",
    "    - 0: probability of the post being predicted as false\n",
    "    - 1: probability of the post being predicted as true\n",
    "    - target: true value\n",
    "    - pred: the predicted value\n",
    "    '''\n",
    "    model.fit(X_test, y_test)\n",
    "    probabilities = model.predict_proba(X_test)\n",
    "    proba_df = pd.DataFrame(probabilities,\n",
    "                           columns=model.classes_, # Getting class names\n",
    "                           index=X_test.index # Setting original index of X_train\n",
    "                           )\n",
    "\n",
    "    proba_df['orig_post'] = X_test\n",
    "    proba_df['target'] = y_test\n",
    "    proba_df['pred'] = model.predict(X_test)\n",
    "    \n",
    "    return proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_df = proba_df(best_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>orig_post</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>0.874051</td>\n",
       "      <td>0.125949</td>\n",
       "      <td>if i survive tonight. i wouldn't change one th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>0.772953</td>\n",
       "      <td>0.227047</td>\n",
       "      <td>i wanna set some shit on fire.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>0.778543</td>\n",
       "      <td>0.221457</td>\n",
       "      <td>reddit's new content policy goes into effect m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>0.498482</td>\n",
       "      <td>0.501518</td>\n",
       "      <td>check out this awesome profile on #ge's swimmi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.575074</td>\n",
       "      <td>0.424926</td>\n",
       "      <td>my car is so fast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0.858455</td>\n",
       "      <td>0.141545</td>\n",
       "      <td>it hurts for me to eat cause i burned my toung...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7206</th>\n",
       "      <td>0.902538</td>\n",
       "      <td>0.097462</td>\n",
       "      <td>so yeah splatoon is still lots of fun and defa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.213216</td>\n",
       "      <td>0.786784</td>\n",
       "      <td>#raining #flooding #florida #tampabay #tampa 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>0.127511</td>\n",
       "      <td>0.872489</td>\n",
       "      <td>rnk issues severe thunderstorm warning [wind: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>0.876569</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>still mortified that when i went to rose's i c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1904 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1                                          orig_post  \\\n",
       "6509  0.874051  0.125949  if i survive tonight. i wouldn't change one th...   \n",
       "3768  0.772953  0.227047            i wanna set some shit on fire.            \n",
       "5507  0.778543  0.221457  reddit's new content policy goes into effect m...   \n",
       "5116  0.498482  0.501518  check out this awesome profile on #ge's swimmi...   \n",
       "18    0.575074  0.424926                         my car is so fast            \n",
       "...        ...       ...                                                ...   \n",
       "1280  0.858455  0.141545  it hurts for me to eat cause i burned my toung...   \n",
       "7206  0.902538  0.097462  so yeah splatoon is still lots of fun and defa...   \n",
       "12    0.213216  0.786784  #raining #flooding #florida #tampabay #tampa 1...   \n",
       "4078  0.127511  0.872489  rnk issues severe thunderstorm warning [wind: ...   \n",
       "1654  0.876569  0.123431  still mortified that when i went to rose's i c...   \n",
       "\n",
       "      target  pred  \n",
       "6509       0     0  \n",
       "3768       1     0  \n",
       "5507       1     0  \n",
       "5116       0     1  \n",
       "18         0     0  \n",
       "...      ...   ...  \n",
       "1280       0     0  \n",
       "7206       0     0  \n",
       "12         1     1  \n",
       "4078       1     1  \n",
       "1654       0     0  \n",
       "\n",
       "[1904 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_preds_1 = proba_df[(proba_df['target'] != proba_df['pred']) & (proba_df['target'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    205.000000\n",
       "mean       0.284105\n",
       "std        0.211113\n",
       "min        0.003462\n",
       "25%        0.103602\n",
       "50%        0.240797\n",
       "75%        0.446237\n",
       "max        0.832493\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(wrong_preds_1[0] - wrong_preds_1[1]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english', max_df=.8, min_df=3)\n",
    "X_test_cvec = cvec.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1409"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing the columns in the X_test_cvec array, thanks John Vinyard from\n",
    "# Stack Overflow: https://stackoverflow.com/questions/13567345/how-to-calculate-the-sum-of-all-columns-of-a-2d-numpy-array-efficiently\n",
    "word_freq = X_test_cvec.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame for word importance\n",
    "word_importance = pd.DataFrame(np.exp(best_nb.named_steps['nb'].coef_.T), index=cvec.get_feature_names())\n",
    "word_importance.columns = ['coefficient']\n",
    "word_importance['testing_word_freq'] = word_freq\n",
    "\n",
    "# Let's sort this by the Coefficient\n",
    "word_importance_sorted = word_importance.sort_values(by='coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this for later\n",
    "word_importance_sorted.to_csv('./data/word_importance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a submission for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv',\n",
       "                 CountVectorizer(max_df=0.8, min_df=3, stop_words='english')),\n",
       "                ('tf', TfidfTransformer(use_idf=False)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on the full training set\n",
    "best_nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text_nolinks'] = df_test['text'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text_nl_hashtag'] = (df_test['text_nolinks'].apply(find_hashtags) + ' ') * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testing = df_test['text_nl_hashtag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_nb.predict(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(df_test['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/submission_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
